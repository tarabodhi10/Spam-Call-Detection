{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21ad60b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank is providing credit card for free So can ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You have win the lucky draw. For verification ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you please share your card details</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Could you please share your card details</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Would you like to share your card details</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>hello you have won lottery of 10 lakhs, can yo...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>You have been selected for holiday package and...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Your phone is looking nice. Do you want to buy...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>There is a sale going on our website. There ar...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>This place looks interesting to visit for today</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text label\n",
       "0    bank is providing credit card for free So can ...  spam\n",
       "1    You have win the lucky draw. For verification ...  spam\n",
       "2               Can you please share your card details  spam\n",
       "3             Could you please share your card details  spam\n",
       "4            Would you like to share your card details  spam\n",
       "..                                                 ...   ...\n",
       "453  hello you have won lottery of 10 lakhs, can yo...  spam\n",
       "454  You have been selected for holiday package and...  spam\n",
       "455  Your phone is looking nice. Do you want to buy...   ham\n",
       "456  There is a sale going on our website. There ar...   ham\n",
       "457    This place looks interesting to visit for today   ham\n",
       "\n",
       "[458 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only 1st time execute  1\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('NewDataSet.csv')#,index_col=0)\n",
    "# df=pd.read_csv('Phishing_Call_Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3fc58c",
   "metadata": {},
   "source": [
    "# ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38d0bcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank is providing credit card for free So can ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You have win the lucky draw. For verification ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you please share your card details</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Could you please share your card details</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Would you like to share your card details</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  bank is providing credit card for free So can ...  spam\n",
       "1  You have win the lucky draw. For verification ...  spam\n",
       "2             Can you please share your card details  spam\n",
       "3           Could you please share your card details  spam\n",
       "4          Would you like to share your card details  spam"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95409aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      bank is providing credit card for free So can ...\n",
       "1      You have win the lucky draw. For verification ...\n",
       "2                 Can you please share your card details\n",
       "3               Could you please share your card details\n",
       "4              Would you like to share your card details\n",
       "                             ...                        \n",
       "453    hello you have won lottery of 10 lakhs, can yo...\n",
       "454    You have been selected for holiday package and...\n",
       "455    Your phone is looking nice. Do you want to buy...\n",
       "456    There is a sale going on our website. There ar...\n",
       "457      This place looks interesting to visit for today\n",
       "Name: text, Length: 458, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "591e88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------\n",
    "def review_messages(msg):\n",
    "    # converting messages to lowercase\n",
    "    msg = msg.lower()\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dba01130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello hi how are you\n"
     ]
    }
   ],
   "source": [
    "print(textt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68f90d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Megha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8680b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saying\n"
     ]
    }
   ],
   "source": [
    "#------------\n",
    "import nltk\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    " \n",
    "s1=lemmatizer.lemmatize('Saying')\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a5cf6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4164ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import stem\n",
    "from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "# lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "stemmer = stem.SnowballStemmer('english')\n",
    "#stopwords = set(stopwords.words('english'))\n",
    "stopwords = ['a','because']\n",
    "\n",
    "def alternative_review_messages(msgs):\n",
    "    # converting messages to lowercase\n",
    "    msgs = msgs.lower()\n",
    "    # removing stopwords\n",
    "    msgs = [word for word in msgs.split() if word not in stopwords] # uncomment aftrwrds\n",
    "    # using a stemmer\n",
    "    msgs = \" \".join([stemmer.stem(word) for word in msgs])\n",
    "#     msgs = \" \".join([lemmatizer.lemmatize(word) for word in msgs])\n",
    "    return msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "225dc087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['megha', 'is', 'learning', 'Machine', 'Learning', 'for', 'Cyber', 'bullying']\n",
      "___ ['megha', 'learning', 'Machine', 'Learning', 'Cyber', 'bullying']\n",
      "['megha', 'learn', 'machin', 'learn', 'cyber', 'bulli']\n",
      "megha learn machin learn cyber bulli\n"
     ]
    }
   ],
   "source": [
    "#-------------\n",
    "ss='megha is learning Machine Learning for Cyber bullying'\n",
    "tt=ss.split()\n",
    "msges=[]\n",
    "print(tt)\n",
    "\n",
    "\n",
    "for i in tt:\n",
    "    if i not in stopwords:\n",
    "        msges.append(i)\n",
    "        \n",
    "print('___',msges)\n",
    "    \n",
    "l1=[]\n",
    "    \n",
    "for i in msges:\n",
    "    l1.append(stemmer.stem(i))\n",
    "    \n",
    "print(l1)\n",
    "a=' '.join(l1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62d1be6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank is providing credit card for free So can ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You have win the lucky draw. For verification ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you please share your card details</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Could you please share your card details</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Would you like to share your card details</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  bank is providing credit card for free So can ...  spam\n",
       "1  You have win the lucky draw. For verification ...  spam\n",
       "2             Can you please share your card details  spam\n",
       "3           Could you please share your card details  spam\n",
       "4          Would you like to share your card details  spam"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22ae7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(alternative_review_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96191d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      bank is provid credit card for free so can you...\n",
       "1      you have win the lucki draw. for verif your ne...\n",
       "2                   can you pleas share your card detail\n",
       "3                 could you pleas share your card detail\n",
       "4               would you like to share your card detail\n",
       "                             ...                        \n",
       "453    hello you have won lotteri of 10 lakhs, can yo...\n",
       "454    you have been select for holiday packag and we...\n",
       "455    your phone is look nice. do you want to buy ac...\n",
       "456    there is sale go on our website. there are man...\n",
       "457          this place look interest to visit for today\n",
       "Name: text, Length: 458, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb39723e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank is provid credit card for free so can you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you have win the lucki draw. for verif your ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can you pleas share your card detail</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>could you pleas share your card detail</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>would you like to share your card detail</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  bank is provid credit card for free so can you...      1\n",
       "1  you have win the lucki draw. for verif your ne...      1\n",
       "2               can you pleas share your card detail      1\n",
       "3             could you pleas share your card detail      1\n",
       "4           would you like to share your card detail      1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['label']=label_encoder.fit_transform(df['label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a698a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e4c46657adfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "#----------\n",
    "print(df.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size = 0.1, random_state = 1,stratify=y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80e5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de3a2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data spliting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size = 0.2, random_state = 1, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2793f109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358    0\n",
       "32     1\n",
       "253    1\n",
       "388    0\n",
       "280    1\n",
       "      ..\n",
       "282    1\n",
       "15     1\n",
       "426    0\n",
       "307    0\n",
       "83     1\n",
       "Name: label, Length: 92, dtype: int32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "503cd3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing (converting into numeric form)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b911105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.73061972,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da2b73d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training model\n",
    "from sklearn import svm\n",
    "svm = svm.SVC(C=1000)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6913604b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32,  1],\n",
       "       [ 0, 59]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "X_test = vectorizer.transform(X_test)\n",
    "y_pred = svm.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3446fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  1]\n",
      " [ 0 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.98      1.00      0.99        59\n",
      "\n",
      "    accuracy                           0.99        92\n",
      "   macro avg       0.99      0.98      0.99        92\n",
      "weighted avg       0.99      0.99      0.99        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-----\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "# X_test = vectorizer.transform(X_test)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4730b596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('expiri date debit card', 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------\n",
    "df['text'].iloc[25],df['label'].iloc[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "101bb716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358    0\n",
       "32     1\n",
       "253    1\n",
       "388    0\n",
       "280    1\n",
       "      ..\n",
       "282    1\n",
       "15     1\n",
       "426    0\n",
       "307    0\n",
       "83     1\n",
       "Name: label, Length: 92, dtype: int32"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0bc00dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0e2786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------\n",
    "def pred(textt):\n",
    "    textt = vectorizer.transform([textt])\n",
    "    prediction = svm.predict(textt)\n",
    "    print(prediction)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b50591e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred('bank is providing credit card for free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecb49e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    48\n",
       "0    17\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f26bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4818f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(svm, open('model_04_2022.pkl', 'wb'))\n",
    "pickle.dump(vectorizer, open('vectorizer_04_2022.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e0b0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------\n",
    "pickled_model = pickle.load(open('model1.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba6471a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#------------\n",
    "textt = vectorizer.transform(['Hello hi how are you'])\n",
    "prediction = pickled_model.predict(textt)\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5852090b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------\n",
    "import pickle\n",
    " \n",
    "# Save the trained model as a pickle string.\n",
    "saved_model = pickle.dumps(svm)\n",
    " \n",
    "# Load the pickled model\n",
    "svm_from_pickle = pickle.loads(saved_model)\n",
    "\n",
    "sms=\"don't give your cvv number of credit card\"\n",
    "textt = vectorizer.transform([sms])\n",
    " \n",
    "# Use the loaded pickled model to make predictions\n",
    "svm_from_pickle.predict(textt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0cf4afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------alternate libary for saving\n",
    "\n",
    "# from sklearn.externals \n",
    "import joblib\n",
    " \n",
    "# Save the model as a pickle in a file\n",
    "joblib.dump(svm, 'model.pkl')\n",
    " \n",
    "# # Load the model from the file\n",
    "# knn_from_joblib = joblib.load('filename.pkl')\n",
    " \n",
    "# # Use the loaded model to make predictions\n",
    "# knn_from_joblib.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869ef72b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
